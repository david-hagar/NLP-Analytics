{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example adapted from: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "Requires jupyter notebooks, keras, and tensorflow installed. My install process was:\n",
    "1. follow instructions for python virtual environment (Virtualenv) install at \n",
    "2. install keras python env using https://keras.io/#installation\n",
    "3. install jupyter notebooks and set up a tensorflow kernel that uses the virtualenv set up above. \n",
    "4. start jupyter notebooks in a parent directory of this notebook and open this notebook. Make sure the Tensorflow Virtualenv jupyter kernel is active when running the notebook.\n",
    "the logs of my install are at: https://www.evernote.com/l/ACtXalW9qSpOVZOUU04V2ATOmJOvw4Ffido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/hagar/apps/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "# docs at: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data \n",
    "top_words = 5000\n",
    "start_char=1\n",
    "oov_char=2\n",
    "index_from=3\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words, \n",
    "                                start_char=start_char, oov_char = oov_char, index_from = index_from )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 500), (25000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 500), (25000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    1,   14,   22,   16,\n",
       "         43,  530,  973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,\n",
       "        173,   36,  256,    5,   25,  100,   43,  838,  112,   50,  670,\n",
       "          2,    9,   35,  480,  284,    5,  150,    4,  172,  112,  167,\n",
       "          2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
       "         13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,\n",
       "         22,    4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,\n",
       "         43,  530,   38,   76,   15,   13, 1247,    4,   22,   17,  515,\n",
       "         17,   12,   16,  626,   18,    2,    5,   62,  386,   12,    8,\n",
       "        316,    8,  106,    5,    4, 2223,    2,   16,  480,   66, 3785,\n",
       "         33,    4,  130,   12,   16,   38,  619,    5,   25,  124,   51,\n",
       "         36,  135,   48,   25, 1415,   33,    6,   22,   12,  215,   28,\n",
       "         77,   52,    5,   14,  407,   16,   82,    2,    8,    4,  107,\n",
       "        117,    2,   15,  256,    4,    2,    7, 3766,    5,  723,   36,\n",
       "         71,   43,  530,  476,   26,  400,  317,   46,    7,    4,    2,\n",
       "       1029,   13,  104,   88,    4,  381,   15,  297,   98,   32, 2071,\n",
       "         56,   26,  141,    6,  194,    2,   18,    4,  226,   22,   21,\n",
       "        134,  476,   26,  480,    5,  144,   30,    2,   18,   51,   36,\n",
       "         28,  224,   92,   25,  104,    4,  226,   65,   16,   38, 1334,\n",
       "         88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,   15,\n",
       "         16,    2,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:20]  # first 20 sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "inv_word_index = np.empty(len(word_index)+index_from+3, dtype=np.object)\n",
    "for k, v in word_index.items():\n",
    "    inv_word_index[v+index_from]=k\n",
    "\n",
    "inv_word_index[0]='<pad>'    \n",
    "inv_word_index[1]='<start>'\n",
    "inv_word_index[2]='<oov>' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16942"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index['ai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_word_index[16942+index_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<pad>', '<start>', '<oov>', None, 'the', 'and', 'a', 'of', 'to',\n",
       "       'is', 'br', 'in', 'it', 'i', 'this', 'that', 'was', 'as', 'for',\n",
       "       'with', 'movie', 'but', 'film', 'on', 'not', 'you', 'are', 'his',\n",
       "       'have', 'he', 'be', 'one', 'all', 'at', 'by', 'an', 'they', 'who',\n",
       "       'so', 'from', 'like', 'her', 'or', 'just', 'about', \"it's\", 'out',\n",
       "       'has', 'if', 'some'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_word_index[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toText(wordIDs):\n",
    "    s = ''\n",
    "    for i in range(len(wordIDs)):\n",
    "        if wordIDs[i] != 0:\n",
    "            w = str(inv_word_index[wordIDs[i]])\n",
    "            s+= w + ' '\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0) sentiment = positive\n",
      "<start> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <oov> is an amazing actor and now the same being director <oov> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <oov> and would recommend it to everyone to watch and the fly <oov> was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <oov> to the two little <oov> that played the <oov> of norman and paul they were just brilliant children are often left out of the <oov> list i think because the stars that play them all grown up are such a big <oov> for the whole film but these children are amazing and should be <oov> for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was <oov> with us all \n",
      "\n",
      "1) sentiment = negative\n",
      "<start> big hair big <oov> bad music and a giant safety <oov> these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an <oov> the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are <oov> and funny in equal <oov> the hair is big lots of <oov> <oov> men wear those cut <oov> <oov> that show off their <oov> <oov> that men actually wore them and the music is just <oov> trash that plays over and over again in almost every scene there is trashy music <oov> and <oov> taking away bodies and the <oov> still doesn't close for <oov> all <oov> aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then \n",
      "\n",
      "2) sentiment = negative\n",
      "<start> this has to be one of the worst films of the <oov> when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <oov> working to watch this <oov> excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <oov> this is to watch save yourself an hour a bit of your life \n",
      "\n",
      "3) sentiment = positive\n",
      "events on the <oov> <oov> a mile or so from where she lives br br of course it happened many years before she was born but you wouldn't guess from the way she tells it the same story is told in <oov> the length and <oov> of <oov> as i <oov> it with a friend one night in <oov> a local cut in to give his version the discussion continued to closing time br br stories passed down like this become part of our being who doesn't remember the stories our parents told us when we were children they become our invisible world and as we grow older they maybe still serve as inspiration or as an emotional <oov> fact and fiction blend with <oov> role models warning stories <oov> magic and mystery br br my name is <oov> like my grandfather and his grandfather before him our protagonist introduces himself to us and also introduces the story that <oov> back through <oov> it <oov> stories within stories stories that <oov> the <oov> wonder of <oov> its <oov> mountains <oov> in <oov> the stuff of legend yet <oov> is <oov> in reality this is what gives it its special charm it has a rough beauty and <oov> <oov> with some of the finest <oov> singing you will ever hear br br <oov> <oov> visits his grandfather in hospital shortly before his death he burns with frustration part of him <oov> to be in the twenty first century to hang out in <oov> but he is raised on the western <oov> among a <oov> speaking community br br yet there is a deeper conflict within him he <oov> to know the truth the truth behind his <oov> ancient stories where does fiction end and he wants to know the truth behind the death of his parents br br he is pulled to make a last <oov> journey to the <oov> of one of <oov> most <oov> mountains can the truth be told or is it all in stories br br in this story about stories we <oov> bloody battles <oov> lovers the <oov> of old and the sometimes more <oov> <oov> of accepted truth in doing so we each connect with <oov> as he lives the story of his own life br br <oov> the <oov> <oov> is probably the most honest <oov> and genuinely beautiful film of <oov> ever made like <oov> i got slightly annoyed with the <oov> of hanging stories on more stories but also like <oov> i <oov> this once i saw the <oov> picture ' forget the box office <oov> of <oov> and its like you might even <oov> the <oov> famous <oov> of the <oov> man to see a film that is true to <oov> this one is probably unique if you maybe <oov> on it deeply enough you might even re <oov> the power of storytelling and the age old question of whether there are some <oov> that cannot be told but only experienced \n",
      "\n",
      "4) sentiment = negative\n",
      "<start> worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon <oov> my head in i stuck that damn movie in the <oov> and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and <oov> a whole day of my life \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print()\n",
    "    print(str(i) + ') sentiment = ' + ('negative' if y_train[i]==0 else 'positive'))\n",
    "    print(toText(X_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 221s 9ms/step - loss: 0.4343 - acc: 0.7951 - val_loss: 0.3165 - val_acc: 0.8687\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 218s 9ms/step - loss: 0.3154 - acc: 0.8735 - val_loss: 0.3580 - val_acc: 0.8480\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 217s 9ms/step - loss: 0.2637 - acc: 0.8970 - val_loss: 0.3050 - val_acc: 0.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ec4e5f8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.71%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
